# Hash Table

## Quick Definition

Array-based data structure that uses hash function to map keys to indices, enabling average O(1) lookup, insert, and delete operations.

## Big-O Summary

| Operation | Average | Worst | Space |
|-----------|---------|-------|-------|
| Get       | **O(1)** | O(n) | O(n) |
| Put       | **O(1)** | O(n) | — |
| Remove    | **O(1)** | O(n) | — |
| Contains  | **O(1)** | O(n) | — |

## Core Operations

```java
// Multiple Map implementations
HashMap<String, Integer> map1 = new HashMap<>();              // fastest, no ordering
LinkedHashMap<String, Integer> map2 = new LinkedHashMap<>();  // insertion order
TreeMap<String, Integer> map3 = new TreeMap<>();              // sorted by keys
ConcurrentHashMap<String, Integer> map4 = new ConcurrentHashMap<>(); // thread-safe

// Initialization options
HashMap<String, Integer> wordCount = new HashMap<>(Map.of(
    "apple", 5, "banana", 3, "cherry", 8
));

// Basic operations
map1.put("key1", 100);                    // insert/update
Integer val = map1.get("key1");           // retrieve: 100
Integer def = map1.getOrDefault("key2", -1); // get with default: -1
boolean exists = map1.containsKey("key1");   // check existence

// Advanced operations
map1.putIfAbsent("key3", 200);            // insert only if absent
map1.merge("key1", 50, Integer::sum);     // merge with function: 150
map1.compute("key4", (k, v) -> v == null ? 1 : v + 1); // compute new value

// Iteration patterns
for (Map.Entry<String, Integer> entry : map1.entrySet()) {
    String key = entry.getKey(); Integer value = entry.getValue();
}
map1.forEach((key, value) -> System.out.println(key + "=" + value));

// HashSet for unique values
HashSet<String> uniqueWords = new HashSet<>(Arrays.asList("a", "b", "c"));
uniqueWords.add("d"); uniqueWords.remove("a");
boolean contains = uniqueWords.contains("b");

// Frequency counting pattern
String[] words = {"apple", "banana", "apple", "cherry"};
Map<String, Integer> freq = new HashMap<>();
for (String word : words) {
    freq.merge(word, 1, Integer::sum);  // increment count
}
```

## Python Snippet

```python
# Dict (hash table) basics
map1 = {}                          # literal
map2 = dict([("apple", 5), ("banana", 3)])

# Basic operations
map1["key1"] = 100                 # insert/update
val = map1.get("key1")             # 100
defaulted = map1.get("key2", -1)   # -1
exists = "key1" in map1

# Advanced operations
map1.setdefault("key3", 200)       # insert only if absent
map1["key1"] = map1.get("key1", 0) + 50
map1["key4"] = 1 + map1.get("key4", 0)

# Iteration
for k, v in map1.items():
    pass

# HashSet equivalent
unique = set(["a", "b", "c"])
unique.add("d"); unique.discard("a")
contains = "b" in unique

# Frequency counting
from collections import Counter, defaultdict
words = ["apple", "banana", "apple", "cherry"]
freq = Counter(words)
freq2 = defaultdict(int)
for w in words:
    freq2[w] += 1
```

## When to Use

- Fast lookups in databases and caching systems
- Frequency counting and duplicate detection
- Implementing sets and unique collections
- Symbol tables in compilers and interpreters
- Database indexing and join operations

## Trade-offs

**Pros:**

- Average O(1) operations for get, put, remove
- Excellent for fast lookups and membership testing
- Memory-efficient for sparse key spaces
- Natural fit for caching and memoization

**Cons:**

- O(n) worst-case due to hash collisions
- No ordering guarantees (except LinkedHashMap, TreeMap)
- Hash function quality affects performance significantly
- Memory overhead for empty buckets and collision handling

## Practice Problems

- **Two Sum**: Use HashMap to find pair with target sum
- **Group Anagrams**: Hash anagram signatures to group words
- **First Unique Character**: Count frequencies then find first unique
- **Valid Anagram**: Compare character frequency maps
- **Intersection of Arrays**: Use HashSet for O(n) intersection

<details>
<summary>Implementation Notes (Advanced)</summary>

### Hash Function Design

- **Good distribution**: Keys should map uniformly across buckets
- **Deterministic**: Same key must always hash to same value
- **Fast computation**: Hash function should be efficient
- **Avalanche effect**: Small key changes should cause large hash changes

### Collision Resolution

- **Chaining**: Each bucket contains linked list of entries
- **Open addressing**: Linear/quadratic probing to find empty slots
- **Robin Hood hashing**: Minimize variance in probe distances

### Load Factor Management

- **Load factor**: ratio of entries to bucket count (typically 0.75)
- **Resize trigger**: When load factor exceeds threshold
- **Rehashing cost**: O(n) operation but amortized over many inserts

### HashMap Variants

- **HashMap**: No ordering, fastest performance
- **LinkedHashMap**: Maintains insertion/access order
- **TreeMap**: Sorted by keys using red-black tree
- **ConcurrentHashMap**: Thread-safe with segment locking

### Performance Considerations

- **Hash code quality**: Poor hash codes cause clustering
- **Bucket distribution**: Uniform distribution minimizes collisions
- **Memory locality**: Open addressing better for cache performance

</details>
